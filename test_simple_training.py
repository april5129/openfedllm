#!/usr/bin/env python3
"""
ç®€å•çš„è”é‚¦å­¦ä¹ æµ‹è¯•è„šæœ¬
ç”¨äºéªŒè¯ç³»ç»Ÿæ˜¯å¦æ­£å¸¸å·¥ä½œ
"""

import os
import sys
import torch
import ray
from transformers import AutoTokenizer, AutoModelForCausalLM
from peft import LoraConfig, get_peft_model

# æ·»åŠ é¡¹ç›®è·¯å¾„
project_root = os.path.dirname(os.path.abspath(__file__))
if project_root not in sys.path:
    sys.path.insert(0, project_root)

def test_basic_imports():
    """æµ‹è¯•åŸºæœ¬å¯¼å…¥"""
    print("ğŸ” æµ‹è¯•åŸºæœ¬å¯¼å…¥...")
    try:
        from algo.FedFT.base_client import BaseClient
        from algo.FedFT.fedavg.server import FedAvgServer
        from dataset.process_dataset import process_sft_dataset
        from utils.template import get_formatting_prompts_func
        print("âœ… æ‰€æœ‰æ¨¡å—å¯¼å…¥æˆåŠŸ")
        return True
    except Exception as e:
        print(f"âŒ å¯¼å…¥å¤±è´¥: {e}")
        return False

def test_ray_cluster():
    """æµ‹è¯•Rayé›†ç¾¤"""
    print("ğŸ” æµ‹è¯•Rayé›†ç¾¤...")
    try:
        if not ray.is_initialized():
            ray.init(
                ignore_reinit_error=True,
                num_cpus=2,
                object_store_memory=500000000,
                _memory=1000000000
            )
        print(f"âœ… Rayé›†ç¾¤çŠ¶æ€: {ray.status()}")
        return True
    except Exception as e:
        print(f"âŒ Rayé›†ç¾¤æµ‹è¯•å¤±è´¥: {e}")
        return False

def test_model_loading():
    """æµ‹è¯•æ¨¡å‹åŠ è½½"""
    print("ğŸ” æµ‹è¯•æ¨¡å‹åŠ è½½...")
    try:
        # ä½¿ç”¨è¾ƒå°çš„æ¨¡å‹è¿›è¡Œæµ‹è¯•
        model_name = "microsoft/DialoGPT-small"
        tokenizer = AutoTokenizer.from_pretrained(model_name)
        model = AutoModelForCausalLM.from_pretrained(model_name)
        
        # æµ‹è¯•PEFTé…ç½®
        peft_config = LoraConfig(
            r=4,
            lora_alpha=8,
            lora_dropout=0.05,
            bias="none",
            task_type="CAUSAL_LM",
        )
        model = get_peft_model(model, peft_config)
        print("âœ… æ¨¡å‹åŠ è½½æˆåŠŸ")
        return True
    except Exception as e:
        print(f"âŒ æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
        return False

def test_dataset_processing():
    """æµ‹è¯•æ•°æ®é›†å¤„ç†"""
    print("ğŸ” æµ‹è¯•æ•°æ®é›†å¤„ç†...")
    try:
        from datasets import load_dataset
        dataset = load_dataset("lucasmccabe-lmi/CodeAlpaca-20k", split="train")
        print(f"âœ… æ•°æ®é›†åŠ è½½æˆåŠŸï¼Œæ ·æœ¬æ•°: {len(dataset)}")
        return True
    except Exception as e:
        print(f"âŒ æ•°æ®é›†å¤„ç†å¤±è´¥: {e}")
        return False

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ å¼€å§‹è”é‚¦å­¦ä¹ ç³»ç»Ÿæµ‹è¯•...")
    print("=" * 50)
    
    # è®¾ç½®ç¯å¢ƒå˜é‡
    os.environ['PYTHONPATH'] = f"{project_root}:{os.environ.get('PYTHONPATH', '')}"
    os.environ['RAY_DISABLE_IMPORT_WARNING'] = '1'
    
    # è¿è¡Œæµ‹è¯•
    tests = [
        test_basic_imports,
        test_ray_cluster,
        test_model_loading,
        test_dataset_processing
    ]
    
    passed = 0
    total = len(tests)
    
    for test in tests:
        try:
            if test():
                passed += 1
        except Exception as e:
            print(f"âŒ æµ‹è¯•å¼‚å¸¸: {e}")
        print("-" * 30)
    
    print(f"ğŸ“Š æµ‹è¯•ç»“æœ: {passed}/{total} é€šè¿‡")
    
    if passed == total:
        print("ğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼ç³»ç»Ÿå‡†å¤‡å°±ç»ªã€‚")
        return True
    else:
        print("âš ï¸  éƒ¨åˆ†æµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥ç³»ç»Ÿé…ç½®ã€‚")
        return False

if __name__ == "__main__":
    success = main()
    if ray.is_initialized():
        ray.shutdown()
    sys.exit(0 if success else 1) 