#!/usr/bin/env python3
"""
è…¾è®¯äº‘æœåŠ¡å™¨ä¸“ç”¨é…ç½®
é’ˆå¯¹è…¾è®¯äº‘æœåŠ¡å™¨çš„ç¡¬ä»¶é…ç½®ä¼˜åŒ–
"""

import os
import torch

# è…¾è®¯äº‘æœåŠ¡å™¨é…ç½®
TENCENT_CLOUD_CONFIG = {
    # æœåŠ¡å™¨åŸºæœ¬ä¿¡æ¯
    "server_ip": "106.52.36.202",
    "server_user": "root",
    "server_password": "@Dsdq0722",
    
    # ç¡¬ä»¶é…ç½®ï¼ˆæ ¹æ®å®é™…æœåŠ¡å™¨é…ç½®è°ƒæ•´ï¼‰
    "cpu_cores": 8,  # CPUæ ¸å¿ƒæ•°
    "memory_gb": 32,  # å†…å­˜å¤§å°
    "gpu_count": 1,   # GPUæ•°é‡ï¼ˆå¦‚æœæœ‰ï¼‰
    "gpu_memory_gb": 8,  # æ¯ä¸ªGPUå†…å­˜
    
    # Rayé›†ç¾¤é…ç½®
    "ray_head_port": 6379,
    "ray_dashboard_port": 8265,
    "ray_object_store_memory": "2000000000",  # 2GB
    "ray_memory": "4000000000",  # 4GB
    
    # è®­ç»ƒé…ç½®
    "num_clients": 4,  # å®¢æˆ·ç«¯æ•°é‡
    "sample_clients": 2,  # æ¯è½®å‚ä¸è®­ç»ƒçš„å®¢æˆ·ç«¯æ•°
    "num_rounds": 50,  # è®­ç»ƒè½®æ•°
    "batch_size": 8,  # æ‰¹æ¬¡å¤§å°
    "learning_rate": 2e-5,  # å­¦ä¹ ç‡
    "max_steps": 100,  # æ¯è½®æœ€å¤§æ­¥æ•°
    
    # æ¨¡å‹é…ç½®
    "model_name": "meta-llama/Llama-2-7b-hf",  # æ¨¡å‹åç§°
    "use_peft": True,  # ä½¿ç”¨PEFT
    "peft_lora_r": 8,  # LoRA rank
    "peft_lora_alpha": 16,  # LoRA alpha
    
    # æ•°æ®é›†é…ç½®
    "dataset_name": "lucasmccabe-lmi/CodeAlpaca-20k",
    "dataset_sample": 5000,  # æ•°æ®é›†é‡‡æ ·æ•°é‡
    
    # è¾“å‡ºé…ç½®
    "output_dir": "/root/openfedllm/output/tencent_cloud_training",
    "save_model_freq": 10,  # ä¿å­˜æ¨¡å‹é¢‘ç‡
}

def get_optimized_training_args():
    """è·å–é’ˆå¯¹è…¾è®¯äº‘æœåŠ¡å™¨ä¼˜åŒ–çš„è®­ç»ƒå‚æ•°"""
    return {
        "num_rounds": TENCENT_CLOUD_CONFIG["num_rounds"],
        "num_clients": TENCENT_CLOUD_CONFIG["num_clients"],
        "sample_clients": TENCENT_CLOUD_CONFIG["sample_clients"],
        "batch_size": TENCENT_CLOUD_CONFIG["batch_size"],
        "learning_rate": TENCENT_CLOUD_CONFIG["learning_rate"],
        "max_steps": TENCENT_CLOUD_CONFIG["max_steps"],
        "save_model_freq": TENCENT_CLOUD_CONFIG["save_model_freq"],
    }

def get_ray_config():
    """è·å–Rayé›†ç¾¤é…ç½®"""
    return {
        "head_port": TENCENT_CLOUD_CONFIG["ray_head_port"],
        "dashboard_port": TENCENT_CLOUD_CONFIG["ray_dashboard_port"],
        "object_store_memory": TENCENT_CLOUD_CONFIG["ray_object_store_memory"],
        "memory": TENCENT_CLOUD_CONFIG["ray_memory"],
        "num_cpus": TENCENT_CLOUD_CONFIG["cpu_cores"],
        "num_gpus": TENCENT_CLOUD_CONFIG["gpu_count"] if torch.cuda.is_available() else 0,
    }

def get_model_config():
    """è·å–æ¨¡å‹é…ç½®"""
    return {
        "model_name_or_path": TENCENT_CLOUD_CONFIG["model_name"],
        "use_peft": TENCENT_CLOUD_CONFIG["use_peft"],
        "peft_lora_r": TENCENT_CLOUD_CONFIG["peft_lora_r"],
        "peft_lora_alpha": TENCENT_CLOUD_CONFIG["peft_lora_alpha"],
        "dataset_name": TENCENT_CLOUD_CONFIG["dataset_name"],
        "dataset_sample": TENCENT_CLOUD_CONFIG["dataset_sample"],
        "output_dir": TENCENT_CLOUD_CONFIG["output_dir"],
    }

def create_tencent_cloud_runner_script():
    """åˆ›å»ºè…¾è®¯äº‘æœåŠ¡å™¨ä¸“ç”¨çš„è¿è¡Œè„šæœ¬"""
    script_content = f'''#!/bin/bash

# è…¾è®¯äº‘æœåŠ¡å™¨ä¸“ç”¨åˆ†å¸ƒå¼è”é‚¦å­¦ä¹ è¿è¡Œè„šæœ¬

echo "ğŸš€ åœ¨è…¾è®¯äº‘æœåŠ¡å™¨ä¸Šå¯åŠ¨åˆ†å¸ƒå¼è”é‚¦å­¦ä¹ è®­ç»ƒ..."

# è®¾ç½®ç¯å¢ƒå˜é‡
export PYTHONPATH="/root/openfedllm:$PYTHONPATH"
export RAY_DISABLE_IMPORT_WARNING=1

# åˆ›å»ºè¾“å‡ºç›®å½•
mkdir -p {TENCENT_CLOUD_CONFIG["output_dir"]}

# å¯åŠ¨Rayé›†ç¾¤
echo "å¯åŠ¨Rayé›†ç¾¤..."
ray start --head --port={TENCENT_CLOUD_CONFIG["ray_head_port"]} \\
    --dashboard-host=0.0.0.0 --dashboard-port={TENCENT_CLOUD_CONFIG["ray_dashboard_port"]} \\
    --object-store-memory={TENCENT_CLOUD_CONFIG["ray_object_store_memory"]} \\
    --memory={TENCENT_CLOUD_CONFIG["ray_memory"]}

# ç­‰å¾…é›†ç¾¤å¯åŠ¨
sleep 10

# æ˜¾ç¤ºé›†ç¾¤çŠ¶æ€
echo "Rayé›†ç¾¤çŠ¶æ€ï¼š"
ray status

# è¿è¡Œåˆ†å¸ƒå¼è®­ç»ƒ
echo "å¼€å§‹åˆ†å¸ƒå¼è”é‚¦å­¦ä¹ è®­ç»ƒ..."
python3 runner/FedFT/distributed_fedavg_runner.py \\
    --model_name_or_path "{TENCENT_CLOUD_CONFIG["model_name"]}" \\
    --dataset_name "{TENCENT_CLOUD_CONFIG["dataset_name"]}" \\
    --num_rounds {TENCENT_CLOUD_CONFIG["num_rounds"]} \\
    --num_clients {TENCENT_CLOUD_CONFIG["num_clients"]} \\
    --sample_clients {TENCENT_CLOUD_CONFIG["sample_clients"]} \\
    --learning_rate {TENCENT_CLOUD_CONFIG["learning_rate"]} \\
    --batch_size {TENCENT_CLOUD_CONFIG["batch_size"]} \\
    --seq_length 512 \\
    --num_train_epochs 1 \\
    --max_steps {TENCENT_CLOUD_CONFIG["max_steps"]} \\
    --output_dir "{TENCENT_CLOUD_CONFIG["output_dir"]}" \\
    --use_peft \\
    --peft_lora_r {TENCENT_CLOUD_CONFIG["peft_lora_r"]} \\
    --peft_lora_alpha {TENCENT_CLOUD_CONFIG["peft_lora_alpha"]} \\
    --template "alpaca" \\
    --dataset_sample {TENCENT_CLOUD_CONFIG["dataset_sample"]}

echo "âœ… åˆ†å¸ƒå¼è”é‚¦å­¦ä¹ è®­ç»ƒå®Œæˆï¼"

# åœæ­¢Rayé›†ç¾¤
ray stop

echo "ğŸ“Š è®­ç»ƒç»“æœä¿å­˜åœ¨: {TENCENT_CLOUD_CONFIG["output_dir"]}"
echo "ğŸ“ˆ æŸ¥çœ‹Ray Dashboard: http://{TENCENT_CLOUD_CONFIG["server_ip"]}:{TENCENT_CLOUD_CONFIG["ray_dashboard_port"]}"
'''
    
    with open("run_tencent_cloud_training.sh", "w") as f:
        f.write(script_content)
    
    # æ·»åŠ æ‰§è¡Œæƒé™
    os.chmod("run_tencent_cloud_training.sh", 0o755)
    print("âœ… è…¾è®¯äº‘æœåŠ¡å™¨ä¸“ç”¨è¿è¡Œè„šæœ¬å·²åˆ›å»º: run_tencent_cloud_training.sh")

def create_monitoring_script():
    """åˆ›å»ºç›‘æ§è„šæœ¬"""
    script_content = f'''#!/bin/bash

# è…¾è®¯äº‘æœåŠ¡å™¨ç›‘æ§è„šæœ¬

echo "ğŸ“Š è…¾è®¯äº‘æœåŠ¡å™¨åˆ†å¸ƒå¼è®­ç»ƒç›‘æ§"
echo "=================================="

# æ£€æŸ¥Rayé›†ç¾¤çŠ¶æ€
echo "ğŸ” æ£€æŸ¥Rayé›†ç¾¤çŠ¶æ€..."
if pgrep -f "ray" > /dev/null; then
    echo "âœ… Rayé›†ç¾¤æ­£åœ¨è¿è¡Œ"
    ray status
else
    echo "âŒ Rayé›†ç¾¤æœªè¿è¡Œ"
fi

# æ£€æŸ¥GPUä½¿ç”¨æƒ…å†µ
echo ""
echo "ğŸ” æ£€æŸ¥GPUä½¿ç”¨æƒ…å†µ..."
if command -v nvidia-smi &> /dev/null; then
    nvidia-smi
else
    echo "âš ï¸  NVIDIA-SMIä¸å¯ç”¨"
fi

# æ£€æŸ¥ç³»ç»Ÿèµ„æº
echo ""
echo "ğŸ” æ£€æŸ¥ç³»ç»Ÿèµ„æº..."
echo "CPUä½¿ç”¨ç‡:"
top -bn1 | grep "Cpu(s)" | awk '{{print $2}}' | cut -d'%' -f1

echo "å†…å­˜ä½¿ç”¨æƒ…å†µ:"
free -h

echo "ç£ç›˜ä½¿ç”¨æƒ…å†µ:"
df -h

# æ£€æŸ¥è®­ç»ƒè¿›ç¨‹
echo ""
echo "ğŸ” æ£€æŸ¥è®­ç»ƒè¿›ç¨‹..."
ps aux | grep -E "(python|ray)" | grep -v grep

# æ£€æŸ¥è¾“å‡ºç›®å½•
echo ""
echo "ğŸ” æ£€æŸ¥è¾“å‡ºç›®å½•..."
if [ -d "{TENCENT_CLOUD_CONFIG["output_dir"]}" ]; then
    echo "âœ… è¾“å‡ºç›®å½•å­˜åœ¨"
    ls -la {TENCENT_CLOUD_CONFIG["output_dir"]}
else
    echo "âŒ è¾“å‡ºç›®å½•ä¸å­˜åœ¨"
fi

echo ""
echo "ğŸ“ˆ Ray Dashboard: http://{TENCENT_CLOUD_CONFIG["server_ip"]}:{TENCENT_CLOUD_CONFIG["ray_dashboard_port"]}"
'''
    
    with open("monitor_tencent_cloud.sh", "w") as f:
        f.write(script_content)
    
    # æ·»åŠ æ‰§è¡Œæƒé™
    os.chmod("monitor_tencent_cloud.sh", 0o755)
    print("âœ… ç›‘æ§è„šæœ¬å·²åˆ›å»º: monitor_tencent_cloud.sh")

if __name__ == "__main__":
    print("ğŸ”§ åˆ›å»ºè…¾è®¯äº‘æœåŠ¡å™¨ä¸“ç”¨é…ç½®...")
    create_tencent_cloud_runner_script()
    create_monitoring_script()
    print("âœ… è…¾è®¯äº‘æœåŠ¡å™¨é…ç½®å®Œæˆï¼") 